<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Kira Chan</title>
    <!-- <link rel="stylesheet" href="./css/reset.css">
    <link rel="stylesheet" href="./css/navbar.css">
    <link rel="stylesheet" href="./css/body.css"> -->
    <link rel="stylesheet" href="./css/main.css">
    <script src="https://code.jquery.com/jquery.min.js"></script>
    <!-- <link rel="icon" href="./favicon.ico" type="image/x-icon"> -->
  </head>
  <body>
    <header id="header">
        
    </header>
    <main id="main">
      <div class="title">MY PROJECTS</div>
        
      <div class="subtitle2">Standing on the shoulders of giants</div>

      <!-- Templating-->
      <!-- <div class="even">
        <div class="paper_title"></div>
        <div class="paper_descriptions">Co-authors: </div>
        <div class="publisher_info">Publisher: </div>
        <div class="download_pdf"><a href="./publications/">PDF</a></div>
        <div class="container">
          <div class="project_subimage"><p></p><img src="./images/projects/" alt=""></div>
          <div class="project_subimage"><p></p><img src="./images/projects/" alt=""></div>
          <div class="project_subimage"><p></p><img src="./images/projects/" alt=""></div>
          <div class="project_subimage2"><p>Double column picture</p><img src="./images/projects/" alt=""></div>
          
        </div>
        <div class="description">
            <p></p>
        </div>
      </div> -->
      
      <!-- SafeDriveRL -->
      <div class="even">
        <div class="paper_title">SafeDriveRL: Combining Non-cooperative Game Theory with Reinforcement Learning to Explore and Mitigate Uncertainty for Autonomous Vehicles</div>
        <div class="paper_descriptions">Co-authors: Sol Zilberman, Nick Polanco, Joshua E. Siegel, and Betty H.C. Cheng</div>
        <div class="publisher_info">Publisher: International Conference on Software Engineering for Adaptive and Self-Managing Systems 2024 (SEAMS)</div>
        <div class="publisher_info">Lisbon, Portugal</div>
        <div class="download_pdf"><a href="https://dl.acm.org/doi/abs/10.1145/3643915.3644089" target="_blank">Conference Proceeding</a></div>
        <div class="container">
          <div class="project_subimage2"><p>Data Flow Diagram</p><img src="./images/projects/safedriverl/dfd-methodology-final.png" alt="DFD for safedriverl"></div>
          <div class="project_subimage"><p>Example of Behaviours Discovered</p><img src="./images/projects/safedriverl/demo.jpg" alt="example of behaviours discovered by SafeDriveRL"></div>
        </div>
        <div class="description">
            <p>Increasingly, artificial intelligence and deep neural networks are used in safety-critical automotive systems, such as self-driving cars. In order to operate safety on the road, these systems must behave correctly in the face of uncertainty, including those that are induced by human behaviour. This work contributes two key insights. First, the interaction between a non-ego human driver vehicle and the ego autonomous vehicle is modelled as a non-cooperative game. As both actors are not aware of the objective / behaviour exhibited by the other party in practice, a non-cooperative game theory approach best models the interaction between the two parties. Second, we use reinforcement learning to train a non-ego vehicle that exhibits a particular type of human behaviour, such as speedy or distracted driving. We evaluate the ability of the ego autonomous vehicle to correctly operate in the face of the non-ego vehicle. We demonstrate that a retrained ego model can better handle the uncertain behaviour exhibited by the non-ego vehicle.</p>
        </div>
      </div>

      <!-- Expound -->
      <div class="odd">
        <div class="paper_title">Expound: A black-box approach for generating diversity-driven adversarial examples</div>
        <div class="paper_descriptions">Co-authors: Betty H.C. Cheng</div>
        <div class="publisher_info">Publisher: International Symposium on Search Based Software Engineering (SSBSE) 2023</div>
        <div class="publisher_info">San Francisco, California, United States</div>
        <div class="download_pdf"><a href="https://link.springer.com/chapter/10.1007/978-3-031-48796-5_2" target="_blank">Conference Proceeding</a></div>
        <div class="container_align">
          <div class="project_subimage2"><p>Expound Generates Diverse Adversarial Examples</p><img src="./images/projects/expound/expound_comparison.png" alt="Comparison of existing work with Expound"></div>
          <div class="project_subimage"><p>Example Diverse Outputs of Expound</p><img src="./images/projects/expound/diverse_sample.png" alt="Expound generates diverse labels"></div>
          <!-- <div class="project_subimage"><p></p><img src="./images/projects/" alt=""></div> -->
          <!-- <div class="project_subimage2"><p>Double column picture</p><img src="./images/projects/" alt=""></div> -->
          
        </div>
        <div class="description">
            <p>A number of existing work introduced adversarial examples (i.e., expected input images with carefully crafted perturbations) and demonstrated their potential impact on DNNs. However, existing work for adversarial examples do not consider diversity (i.e., different ways a model may fail). In this project, we developed a two-step novelty search-based algorithm in order to discover a number of ways a DNN may fail, based on the exploration and exploitation paradigm in evolutionary computing. First, <span class="small_caps">Kobalos</span> uses a high level exploration search to identify the number of ways a model may fail. Second, <span class="small_caps">Tarand</span> exploits the information discovered by <span class="small_caps">Kobalos</span> and discovers a number of adversarial example with different perturbation filter that lead to the same failure category. This information enables developer to better understand the nature of the DNN and develop appropriate mitigation strategies or retraining for the DNN model.</p>
        </div>
      </div>

      <!-- EvoAttack -->
      <div class="even">
        <div class="paper_title">EvoAttack: An evolutionary search-based adversarial attack for object detection models</div>
        <div class="paper_descriptions">Co-authors: Betty H.C. Cheng</div>
        <div class="publisher_info">Publisher: International Symposium on Search Based Software Engineering (SSBSE) 2022</div>
        <div class="publisher_info">Singapore</div>
        <div class="download_pdf"><a href="https://link.springer.com/chapter/10.1007/978-3-031-21251-2_6" target="_blank">Conference Proceeding</a></div>
        <div class="publisher_info">Journal Publisher: Automated SE Journal (ASE) - Special Issue on Advances in Search-based Software Engineering</div>
        <div class="download_pdf">Accepted September 2024, Coming Soon!</div>
        <div class="container">
          <div class="project_subimage2"><p>Adversarial Example Generated Against a Waymo Image</p><img src="./images/projects/evoattack/waymo_adversarial_example.jpg" alt=""></div>
          <!-- <div class="project_subimage"><p></p><img src="./images/projects/" alt=""></div>
          <div class="project_subimage"><p></p><img src="./images/projects/" alt=""></div> -->
          <!-- <div class="project_subimage2"><p>Double column picture</p><img src="./images/projects/" alt=""></div> -->
          
        </div>
        <div class="description">
            <p>State-of-the-art DNNs are being increasing used in a range of real-world applications, including those that are safety-critical (e.g., autonomous driving, medical imaging, etc.). In this project, we demonstrate that adversarial examples, images with carefully crafted minor perturbations, extend to object detection algorithms. This work explores how black-box evolutionary search-based techniques can attack state-of-the-art object detection algorithms. We demonstrate our approach on several datasets (including an autonomous driving dataset) with different DNN models. Preliminary results show that EvoAttack is capable of preventing the detection of any object in the images.</p>
        </div>
      </div>

      <!-- Modalas -->
      <div class="odd">
        <div class="paper_title">MoDALAS: Addressing assurance for learning-enabled autonomous systems in the face of uncertainty</div>
        <div class="paper_descriptions">Co-authors: Michael Austin Langford, Jonathon Emil Fleck, Philip K McKinley, and Betty H.C. Cheng</div>
        <div class="publisher_info">Conference Publisher: 2021 ACM/IEEE 24th International Conference on Model Driven Engineering Languages and Systems (MODELS)</div>
        <div class="download_pdf"><a href="https://ieeexplore.ieee.org/abstract/document/9592499" target="_blank">Conference Proceeding</a></div>
        <div class="publisher_info">Journal Publisher: Software and Systems Modeling (SoSym 2023)</div>
        <div class="download_pdf"><a href="https://link.springer.com/article/10.1007/s10270-023-01090-9" target="_blank">Journal Publication</a></div>
        <!-- <div class="download_pdf"><a href="./publications/langford2021modalas.pdf" target="_blank">Conference Proceeding</a> <a href="./publications/langford2023modalas.pdf" target="_blank">Journal Publication</a></div> -->
        <div class="container_align">
          <div class="project_subimage2"><p>Data Flow Diagram</p><img src="./images/projects/modalas/modalas_dfd.jpg" alt="DFD for modalas"></div>
          <div class="project_subimage"><p>Enlil Simulated Conditions</p><img src="./images/projects/modalas/enlil_generated.jpg" alt="example output of enlil's simulated environmental effects."></div>
        </div>
        <div class="description">
            <p>As Learning-Enabled Components (LECs) are increasingly used in safety-critical systems as key decision making processes, the assurance of their correctness is paramount. However, when training environment fails to fully capture real-world phenomena, the behaviour of the LECs is potentially uncertain, and thus cannot be assured as safe. MoDALAS introduces a model-driven approach to manage the self-adaptation of Learning-Enabled Systems (LES) to account for run-time contexts for which the LEC cannot be trusted. Our framework enables a behaviour oracle to monitor and evaluate goal models at run time to determine whether or not the LECs can meet functional objectives, and enable adaptation should it be deemed untrustworthy.</p>
        </div>
      </div>

      <!-- Towards a Blockchain Framework for Autonomous Vehicle System Integrity -->
      <div class="even">
        <div class="paper_title">Towards a blockchain framework for autonomous vehicle system integrity</div>
        <div class="paper_descriptions">Co-authors: Matthew Pasco and Betty H.C. Cheng</div>
        <div class="publisher_info">Publisher: SAE International Journal of Transportation Cybersecurity and Privacy-V130-11EJ</div>
        <!-- <div class="download_pdf"><a href="./publications/chan2022towardsblockchain.pdf" target="_blank">Journal Publication</a></div> -->
        <div class="download_pdf"><a href="https://www.sae.org/publications/technical-papers/content/11-04-01-0002/" target="_blank">Journal Publication</a></div>
        <div class="container_align">
          <div class="project_subimage"><p>Data Flow Diagram</p><img src="./images/projects/blockchain/blockchain_dfd.jpg" alt="DFD of the blockchain project."></div>
          <div class="project_subimage"><p>Test Bed</p><img src="./images/projects/blockchain/testbed.jpg" alt="test bed computing devices used to mimic ECUs."></div>
          <div class="project_subimage" ><p>ECU Update Process</p><img src="./images/projects/blockchain/ecu_update_process.jpg" alt="Update Process for ECUs."></div>
        </div>
        <div class="description">
            <p>Traditionally, Electronic Control Units (ECUs) in vehicles have been left unsecured. Ensuring cybersecurity in an ECU network is challenging as there is no centralized authority in the vehicle to provide security as a service. While progress has been made to address cybersecurity vulnerabilities, many of these approaches have focused on enterprise, software-centric systems and require more computational resources than typically available for onboard vehicular devices. Furthermore, vehicle networks have the additional challenge of mitigating security vulnerabilities while satisfying safety and performance constraints. This article introduces a blockchain framework which uses extra onboard computing power to detect unauthorized modifications to vehicle ECUs. A proof of concept blockchain prototype framework is implemented on a set of microprocessors (comparable to those used by simple ECUs) as a means to assess the efficacy of using our blockchain approach to detect unauthorized updates.</p>
        </div>
    </div>

    </main>

    
    
    <footer id="footer"></footer>
	
    <script src="./js/index.js" defer></script>
    <script src="./js/navbar.js" defer></script>
    <script src="./js/hamburger.js" defer></script>
    <script src="./js/copyright.js" defer></script>
  </body>
</html>