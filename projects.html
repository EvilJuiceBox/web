<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Kira Chan</title>
    <!-- <link rel="stylesheet" href="./css/reset.css">
    <link rel="stylesheet" href="./css/navbar.css">
    <link rel="stylesheet" href="./css/body.css"> -->
    <link rel="stylesheet" href="./css/main.css">
    <script src="https://code.jquery.com/jquery.min.js"></script>
    <!-- <link rel="icon" href="./favicon.ico" type="image/x-icon"> -->
  </head>
  <body>
    <header id="header">
        
    </header>
    <main id="main">
      <div class="title">MY PROJECTS</div>
        
      <div class="subtitle2">Standing on the shoulders of giants</div>

      <!-- Templating-->
      <!-- <div class="even">
        <div class="paper_title"></div>
        <div class="paper_descriptions">Co-authors: </div>
        <div class="publisher_info">Publisher: </div>
        <div class="download_pdf"><a href="./publications/">PDF</a></div>
        <div class="container">
          <div class="project_subimage"><p></p><img src="./images/projects/" alt=""></div>
          <div class="project_subimage"><p></p><img src="./images/projects/" alt=""></div>
          <div class="project_subimage"><p></p><img src="./images/projects/" alt=""></div>
          <div class="project_subimage2"><p>Double column picture</p><img src="./images/projects/" alt=""></div>
          
        </div>
        <div class="description">
            <p></p>
        </div>
      </div> -->

      <div class="odd">
        <div class="paper_title">Expound: A black-box approach for generating diversity-driven adversarial examples</div>
        <div class="paper_descriptions">Co-authors: Betty H.C. Cheng</div>
        <div class="publisher_info">Publisher: International Symposium on Search Based Software Engineering 2023</div>
        <div class="download_pdf"><p>Accepted to SSBSE 2023, coming soon!</p></div>
        <div class="container_align">
          <div class="project_subimage2"><p>Expound generates diverse adversarial examples</p><img src="./images/projects/expound/expound_comparison.png" alt="Comparison of existing work with Expound"></div>
          <div class="project_subimage"><p>Diverse outputs</p><img src="./images/projects/expound/diverse_sample.png" alt="Expound generates diverse labels"></div>
          <!-- <div class="project_subimage"><p></p><img src="./images/projects/" alt=""></div> -->
          <!-- <div class="project_subimage2"><p>Double column picture</p><img src="./images/projects/" alt=""></div> -->
          
        </div>
        <div class="description">
            <p>A number of existing work introduced adversarial examples (i.e., expected input images with carefully crafted perturbations) and demonstrated their potential impact of DNNs. However, existing work for adversarial examples do not consider diversity (i.e., different ways a model may fail). In this project, we developed a novelty search-based algorithm in order to discover a number of ways a DNN may fail. This information enables developer to better understand the nature of the DNN and develop appropriate mitigation strategies or retraining for the DNN model. </p>
        </div>
      </div>

      <!-- EvoAttack -->
      <div class="even">
        <div class="paper_title">EvoAttack: An evolutionary search-based adversarial attack for object detection models</div>
        <div class="paper_descriptions">Co-authors: Betty H.C. Cheng</div>
        <div class="publisher_info">Publisher: International Symposium on Search Based Software Engineering 2022</div>
        <div class="download_pdf"><a href="./publications/chan2022evoattack.pdf">Conference Proceeding</a></div>
        <div class="container">
          <div class="project_subimage2"><p>Adversarial example generated against a Waymo image.</p><img src="./images/projects/evoattack/waymo_adversarial_example.jpg" alt=""></div>
          <!-- <div class="project_subimage"><p></p><img src="./images/projects/" alt=""></div>
          <div class="project_subimage"><p></p><img src="./images/projects/" alt=""></div> -->
          <!-- <div class="project_subimage2"><p>Double column picture</p><img src="./images/projects/" alt=""></div> -->
          
        </div>
        <div class="description">
            <p>State-of-the-art DNNs are being increasing used in a range of real-world applications, including those that are safety-critical (e.g., autonomous driving, medical imaging, etc.). We demonstrate in this project that adversarial examples, images with carefully crafted minor perturbations, extend to object detection algorithms. This work explores how black-box evolutionary search-based techniques can attack state-of-the-art object detection algorithms. We demonstrate our approach on several dataset (including an autonomous driving dataset) with different DNN models. We demonstrate that our approach is capable of prevent the correct detection of objects in images.</p>
        </div>
      </div>

      <!-- Modalas -->
      <div class="odd">
        <div class="paper_title">MoDALAS: Addressing assurance for learning-enabled autonomous systems in the face of uncertainty</div>
        <div class="paper_descriptions">Co-authors: Michael Austin Langford, Jonathon Emil Fleck, Philip K McKinley, and Betty H.C Cheng</div>
        <div class="publisher_info">Publisher: Software and Systems Modeling (Springer Link)</div>
        <div class="download_pdf"><a href="./publications/langford2021modalas.pdf">Conference Proceeding</a> <a href="./publications/langford2023modalas.pdf">Journal Publication</a></div>
        <div class="container_align">
          <div class="project_subimage2"><p>Data Flow Diagram</p><img src="./images/projects/modalas/modalas_dfd.jpg" alt="DFD for modalas"></div>
          <div class="project_subimage"><p>Enlil Simulated Conditions.</p><img src="./images/projects/modalas/enlil_generated.jpg" alt="example output of enlil's simulated environmental effects."></div>
        </div>
        <div class="description">
            <p>As Learning-Enabled Components (LECs) are increasingly used in safety-critical systems as key decision making processes, the assurance of their correctness is paramount. However, when training environment fails to fully capture real-world phenomena, the behaviour of the LECs is potentially uncertain, and thus cannot be assured as safe. We introduce a model-driven approach to manage the self-adaptation of the Learning-Enabled System (LES) to account for run-time contexts for which the LEC cannot be trusted. The framework enables a behaviour oracle to monitor and evaluate goal models at run time to determine whether or not the LECs can meet functional objectives, and enable adaptation should it not be trusted.</p>
        </div>
      </div>

      <!-- Towards a Blockchain Framework for Autonomous Vehicle System Integrity -->
      <div class="even">
        <div class="paper_title">Towards a blockchain framework for autonomous vehicle system integrity</div>
        <div class="paper_descriptions">Co-authors: Matthew Pasco, Betty H.C. Cheng</div>
        <div class="publisher_info">Publisher: SAE International Journal of Transportation Cybersecurity and Privacy-V130-11EJ</div>
        <div class="download_pdf"><a href="./publications/chan2022towardsblockchain.pdf">Journal Publication</a></div>
        <div class="container_align">
          <div class="project_subimage"><p>Data Flow Diagram</p><img src="./images/projects/blockchain/blockchain_dfd.jpg" alt="DFD of the blockchain project."></div>
          <div class="project_subimage"><p>Test bed</p><img src="./images/projects/blockchain/testbed.jpg" alt="test bed computing devices used to mimic ECUs."></div>
          <div class="project_subimage" ><p>ECU Update Process</p><img src="./images/projects/blockchain/ecu_update_process.jpg" alt="Update Process for ECUs."></div>
        </div>
        <div class="description">
            <p>Traditionally, Electronic Control Units (ECUs) in vehicles have been left unsecured. Ensuring cybersecurity in an ECU network is challenging as there is no centralized authority in the vehicle to provide security as a service. While progress has been made to address cybersecurity vulnerabilities, many of these approaches have focused on enterprise, software-centric systems and require more computational resources than typically available for onboard vehicular devices. Furthermore, vehicle networks have the additional challenge of mitigating security vulnerabilities while satisfying safety and performance constraints. This article introduces a blockchain framework which uses extra onboard computing power to detect unauthorized modifications to vehicle ECUs. A proof of concept blockchain prototype framework is implemented on a set of microprocessors (comparable to those used by simple ECUs) as a means to assess the efficacy of using our blockchain approach to detect unauthorized updates</p>
        </div>
    </div>

    </main>

    
    
    <footer>Â© 2023 Kira Chan</footer>
	
    <script src="./js/index.js" defer></script>
    <script src="./js/navbar.js" defer></script>
    <script src="./js/hamburger.js" defer></script>
  </body>
</html>